# ğŸ›’ **Amharic-NER-LLM-EcomInsightsEthiopia**
A comprehensive repository dedicated to **extracting insights** and **data** from Telegram channels, aimed at **optimizing** the e-commerce landscape in Ethiopia.

### ğŸ” **Overview**
This repository serves as a framework for leveraging **Named Entity Recognition (NER)** in the Amharic language, specifically tailored for e-commerce applications.

## Selected Channels
The following Ethiopian-based Telegram e-commerce channels have been selected for data ingestion:
- **@ethio_brand_collection**

## ğŸ“‚ **Project Structure**

```
+---.github
| â””â”€â”€ workflows
| â””â”€â”€ blank.yml
+---.vscode
| â””â”€â”€ settings.json
+---notebooks
| â”œâ”€â”€ data_processing.ipynb
| â”œâ”€â”€ fine_tunning.ipynb
| â”œâ”€â”€ init.ipynb
| â””â”€â”€ README.md
+---scripts
| â”œâ”€â”€ data_labeler.py
| â”œâ”€â”€ data_preprocessor.py
| â”œâ”€â”€ data_scrapper.py
| â”œâ”€â”€ init.py
| â””â”€â”€ README.md
+---src
| â””â”€â”€ README.md
| â””â”€â”€ init.py
+---tests
| â”œâ”€â”€ README.md
| â””â”€â”€ init.py
| â””â”€â”€ test_data_labeler.py
| â””â”€â”€ test_data_preprocessing.py
| â””â”€â”€test_data_scrapper.py
| â”œâ”€â”€ .gitignore
| â”œâ”€â”€ labeled_data_conll.conll
| â”œâ”€â”€ README.md
| â””â”€â”€ requirements.txt
```

## ğŸ› ï¸ Tools and Libraries
- **Python**: The primary programming language used for the implementation.
- **Telethon**: A Python library for interacting with Telegramâ€™s API to scrape messages.
- **Pandas**: For data manipulation and storage in structured formats.
- **NLTK or SpaCy**: For text preprocessing and tokenization specific to Amharic linguistic features.

## ğŸš€ Installation Instructions
To run the project locally, follow these steps:

Clone the Repository:
`git clone https://github.com/Amen-Zelealem/Amharic-NER-LLM-EcomInsightsEthiopia.git`


`cd Amharic-NER-LLM-EcomInsightsEthiopia`

Set up the Virtual Environment:

`python3 -m venv .venv`
`source .venv/bin/activate  # For Windows: .venv\Scripts\activate`

Install Dependencies:

`pip install -r requirements.txt`

## Models Evaluated ğŸ¤–
1. **XLM-Roberta**
   - Pre-trained on 100 languages, including Amharic. ğŸŒ
   - Excellent for multilingual tasks with extensive contextual understanding.

2. **DistilBERT**
   - A lighter, faster version of BERT. âš¡
   - Suitable for resource-constrained environments while maintaining accuracy.

3. **mBERT (Multilingual BERT)**
   - A widely recognized baseline for multilingual NER tasks. ğŸ“š
   - Pre-trained on various languages, including Amharic.

## Fine-Tuning Process âš™ï¸
- **Epochs**: Each model was fine-tuned over three epochs.
- **Batch Size**: Set to 16 to optimize memory usage.
- **Evaluation Metrics**: Models were assessed using precision, recall, and F1-score.
- **Dataset Size**: 27,989 labeled examples.

## Results Summary ğŸ“Š
### XLM-Roberta
- **Precision**: 0.976126
- **Recall**: 0.975527
- **F1 Score**: 0.963443

### DistilBERT
- **Precision**: 0.967977
- **Recall**: 0.966880
- **F1 Score**: 0.950599

### mBERT
- **Precision**: 0.989941
- **Recall**: 0.988556
- **F1 Score**: 0.989045

## Conclusion ğŸ‰
- **Best Performer**: mBERT demonstrated the highest performance across all metrics, making it the preferred choice for NER tasks in this context.
- **Next Steps**: Further fine-tuning on mBERT and exploration of different training strategies for XLM-Roberta could yield even better results.

## Acknowledgments ğŸ™
Special thanks to the contributors and the community for their support in this project.

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository.
   
2. Create a new branch: 
   
```git checkout -b feature-branch```  

3. Make your changes and commit: 

```git commit -m 'Add new feature'```
  
4. Push to the branch:
 
```git push origin feature-branch```

5. Open a pull request.

Feel free to reach out using the contact below:

âœ‰ï¸ [Amen-Zelealem](mailto:amenzelealem@gmail.com)

# **ğŸŒŸ Elevate Your E-commerce Insights with Real-Time Intelligence!**
