{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Amharic Text Processing and Labeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import logging\n",
    "import os \n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the 'scripts' directory to the Python path for module imports\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'scripts')))\n",
    "# Import data preprocessor and labeler classes\n",
    "from data_preprocessor import AmharicTextPreprocessor\n",
    "from data_labeler import AmharicLabeler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set max rows and columns to display\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-17 18:50:52,571 - INFO - âœ… Imported libraries and configured logging.\n"
     ]
    }
   ],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, \n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logger.info(\"âœ… Imported libraries and configured logging.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: d:\\KAIM\\KIAM-week-6\\EcomInsightsEthiopia\\notebooks\n"
     ]
    }
   ],
   "source": [
    "# Check the current working directory\n",
    "print(\"Current working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame loaded with shape: (600, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load your DataFrame using a relative path\n",
    "df = pd.read_csv('../data/telegram_messages.csv')\n",
    "print(\"DataFrame loaded with shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      " messages    231\n",
      "dtype: int64\n",
      "Columns in the DataFrame: Index(['messages'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Let's check the missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing values in each column:\\n\", missing_values)\n",
    "\n",
    "print(\"Columns in the DataFrame:\", df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Amharic text: áŠ á‹µáˆ«áˆ»-áˆœáŠ­áˆ²áŠ® áŠ®áˆœáˆ­áˆµ áŒ€áˆ­á‰£ áˆ˜á‹šá‹µ á•áˆ‹á‹› á‹¨áˆ˜áŒ€áˆ˜áˆªá‹« á‹°áˆ¨áŒƒ áŠ¥áŠ•á‹°á‹ˆáŒ¡ 101 á‹¨á‰¢áˆ® á‰áŒ¥áˆ­ á‹«áŒˆáŠ™áŠ“áˆ\n",
      "Text preprocessing completed. Sample tokens:\n",
      "                                             messages  \\\n",
      "0  Under armour Goretex\\nSize 40,41,42,43\\nPrice ...   \n",
      "1  ğŸ¥³áˆˆáŒ¥áˆá‰€á‰µ áŠ¥áŠ•á‹²áˆáˆ áˆˆá‰°áˆˆá‹«á‹© á‰ á‹“áˆ‹á‰µ á‹ˆá‹­áˆ á•áˆ®áŒáˆ«áˆ á‹¨áˆšáˆ†áŠ‘ á¥\\n\\nWh...   \n",
      "2  Nike Air Force Goretex\\nSize 40,41,42,43\\nPric...   \n",
      "3  Nike air zoom pegasus running \\nSize 40,41,42,...   \n",
      "4  Adidas terrex running \\nsize 41,42,43\\nPrice 3...   \n",
      "\n",
      "                                preprocessed_message  \n",
      "0  40414243 3500 áŠ á‹µáˆ«áˆ»áˆœáŠ­áˆ²áŠ® áŠ®áˆœáˆ­áˆµ áŒ€áˆ­á‰£ áˆ˜á‹šá‹µ áˆ‹á‹› á‹¨áˆ˜áŒ€áˆ˜áˆªá‹« ...  \n",
      "1  áˆˆáŒ¥áˆá‰€á‰µ áŠ¥áŠ•á‹²áˆáˆ áˆˆá‰°áˆˆá‹«á‹© á‰ á‹“áˆ‹á‰µ á‹ˆá‹­áˆ áˆ®áŒáˆ«áˆ á‹¨áˆšáˆ†áŠ‘ 404142434...  \n",
      "2  40414243 3800 áŠ á‹µáˆ«áˆ»áˆœáŠ­áˆ²áŠ® áŠ®áˆœáˆ­áˆµ áŒ€áˆ­á‰£ áˆ˜á‹šá‹µ áˆ‹á‹› á‹¨áˆ˜áŒ€áˆ˜áˆªá‹« ...  \n",
      "3  40414243 3400 áŠ á‹µáˆ«áˆ»áˆœáŠ­áˆ²áŠ® áŠ®áˆœáˆ­áˆµ áŒ€áˆ­á‰£ áˆ˜á‹šá‹µ áˆ‹á‹› á‹¨áˆ˜áŒ€áˆ˜áˆªá‹« ...  \n",
      "4  414243 3600 áŠ á‹µáˆ«áˆ»áˆœáŠ­áˆ²áŠ® áŠ®áˆœáˆ­áˆµ áŒ€áˆ­á‰£ áˆ˜á‹šá‹µ áˆ‹á‹› á‹¨áˆ˜áŒ€áˆ˜áˆªá‹« á‹°áˆ¨...  \n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Amharic text sample\n",
    "    amharic_text = \"áŠ á‹µáˆ«áˆ»-áˆœáŠ­áˆ²áŠ® áŠ®áˆœáˆ­áˆµ áŒ€áˆ­á‰£ áˆ˜á‹šá‹µ á•áˆ‹á‹› á‹¨áˆ˜áŒ€áˆ˜áˆªá‹« á‹°áˆ¨áŒƒ áŠ¥áŠ•á‹°á‹ˆáŒ¡ 101 á‹¨á‰¢áˆ® á‰áŒ¥áˆ­ á‹«áŒˆáŠ™áŠ“áˆ\"\n",
    "    print(\"Sample Amharic text:\", amharic_text)\n",
    "\n",
    "    preprocessor = AmharicTextPreprocessor()\n",
    "\n",
    "    # Preprocess the text\n",
    "    tokens = preprocessor.preprocess_dataframe(df, 'messages')\n",
    "    print(\"Text preprocessing completed. Sample tokens:\\n\", tokens.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped NaN values from 'messages'. New shape: (369, 2)\n"
     ]
    }
   ],
   "source": [
    "# Drop NaN values in 'messages' column\n",
    "df.dropna(subset='messages', inplace=True)\n",
    "print(\"Dropped NaN values from 'messages'. New shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed texts have been stored. New DataFrame shape: (343, 2)\n"
     ]
    }
   ],
   "source": [
    "# Ensure there are no NaN values in the preprocessed column\n",
    "preprocessed_texts = tokens['preprocessed_message'].dropna().tolist()\n",
    "df = pd.Series(preprocessed_texts).reset_index(name='message')\n",
    "print(\"Preprocessed texts have been stored. New DataFrame shape:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Initialize Labler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the labeler\n",
    "labeler = AmharicLabeler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization completed. Sample tokenized messages:\n",
      " 0    [40414243, 3500, áŠ á‹µáˆ«áˆ»áˆœáŠ­áˆ²áŠ®, áŠ®áˆœáˆ­áˆµ, áŒ€áˆ­á‰£, áˆ˜á‹šá‹µ, áˆ‹á‹›,...\n",
      "1    [áˆˆáŒ¥áˆá‰€á‰µ, áŠ¥áŠ•á‹²áˆáˆ, áˆˆá‰°áˆˆá‹«á‹©, á‰ á‹“áˆ‹á‰µ, á‹ˆá‹­áˆ, áˆ®áŒáˆ«áˆ, á‹¨áˆšáˆ†áŠ‘, 4...\n",
      "2    [40414243, 3800, áŠ á‹µáˆ«áˆ»áˆœáŠ­áˆ²áŠ®, áŠ®áˆœáˆ­áˆµ, áŒ€áˆ­á‰£, áˆ˜á‹šá‹µ, áˆ‹á‹›,...\n",
      "3    [40414243, 3400, áŠ á‹µáˆ«áˆ»áˆœáŠ­áˆ²áŠ®, áŠ®áˆœáˆ­áˆµ, áŒ€áˆ­á‰£, áˆ˜á‹šá‹µ, áˆ‹á‹›,...\n",
      "4    [414243, 3600, áŠ á‹µáˆ«áˆ»áˆœáŠ­áˆ²áŠ®, áŠ®áˆœáˆ­áˆµ, áŒ€áˆ­á‰£, áˆ˜á‹šá‹µ, áˆ‹á‹›, á‹¨...\n",
      "Name: Tokenized, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the messages\n",
    "df['Tokenized'] = df['message'].apply(lambda x: x.split())\n",
    "print(\"Tokenization completed. Sample tokenized messages:\\n\", df['Tokenized'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeling completed. Sample labeled DataFrame:\n",
      "    index                                            message  \\\n",
      "0      0  40414243 3500 áŠ á‹µáˆ«áˆ»áˆœáŠ­áˆ²áŠ® áŠ®áˆœáˆ­áˆµ áŒ€áˆ­á‰£ áˆ˜á‹šá‹µ áˆ‹á‹› á‹¨áˆ˜áŒ€áˆ˜áˆªá‹« ...   \n",
      "1      1  áˆˆáŒ¥áˆá‰€á‰µ áŠ¥áŠ•á‹²áˆáˆ áˆˆá‰°áˆˆá‹«á‹© á‰ á‹“áˆ‹á‰µ á‹ˆá‹­áˆ áˆ®áŒáˆ«áˆ á‹¨áˆšáˆ†áŠ‘ 404142434...   \n",
      "2      2  40414243 3800 áŠ á‹µáˆ«áˆ»áˆœáŠ­áˆ²áŠ® áŠ®áˆœáˆ­áˆµ áŒ€áˆ­á‰£ áˆ˜á‹šá‹µ áˆ‹á‹› á‹¨áˆ˜áŒ€áˆ˜áˆªá‹« ...   \n",
      "3      3  40414243 3400 áŠ á‹µáˆ«áˆ»áˆœáŠ­áˆ²áŠ® áŠ®áˆœáˆ­áˆµ áŒ€áˆ­á‰£ áˆ˜á‹šá‹µ áˆ‹á‹› á‹¨áˆ˜áŒ€áˆ˜áˆªá‹« ...   \n",
      "4      4  414243 3600 áŠ á‹µáˆ«áˆ»áˆœáŠ­áˆ²áŠ® áŠ®áˆœáˆ­áˆµ áŒ€áˆ­á‰£ áˆ˜á‹šá‹µ áˆ‹á‹› á‹¨áˆ˜áŒ€áˆ˜áˆªá‹« á‹°áˆ¨...   \n",
      "\n",
      "                                           Tokenized  \\\n",
      "0  [40414243, 3500, áŠ á‹µáˆ«áˆ»áˆœáŠ­áˆ²áŠ®, áŠ®áˆœáˆ­áˆµ, áŒ€áˆ­á‰£, áˆ˜á‹šá‹µ, áˆ‹á‹›,...   \n",
      "1  [áˆˆáŒ¥áˆá‰€á‰µ, áŠ¥áŠ•á‹²áˆáˆ, áˆˆá‰°áˆˆá‹«á‹©, á‰ á‹“áˆ‹á‰µ, á‹ˆá‹­áˆ, áˆ®áŒáˆ«áˆ, á‹¨áˆšáˆ†áŠ‘, 4...   \n",
      "2  [40414243, 3800, áŠ á‹µáˆ«áˆ»áˆœáŠ­áˆ²áŠ®, áŠ®áˆœáˆ­áˆµ, áŒ€áˆ­á‰£, áˆ˜á‹šá‹µ, áˆ‹á‹›,...   \n",
      "3  [40414243, 3400, áŠ á‹µáˆ«áˆ»áˆœáŠ­áˆ²áŠ®, áŠ®áˆœáˆ­áˆµ, áŒ€áˆ­á‰£, áˆ˜á‹šá‹µ, áˆ‹á‹›,...   \n",
      "4  [414243, 3600, áŠ á‹µáˆ«áˆ»áˆœáŠ­áˆ²áŠ®, áŠ®áˆœáˆ­áˆµ, áŒ€áˆ­á‰£, áˆ˜á‹šá‹µ, áˆ‹á‹›, á‹¨...   \n",
      "\n",
      "                                             Labeled  \n",
      "0  [(40414243, O), (3500, O), (áŠ á‹µáˆ«áˆ»áˆœáŠ­áˆ²áŠ®, O), (áŠ®áˆœáˆ­...  \n",
      "1  [(áˆˆáŒ¥áˆá‰€á‰µ, O), (áŠ¥áŠ•á‹²áˆáˆ, O), (áˆˆá‰°áˆˆá‹«á‹©, O), (á‰ á‹“áˆ‹á‰µ, O)...  \n",
      "2  [(40414243, O), (3800, O), (áŠ á‹µáˆ«áˆ»áˆœáŠ­áˆ²áŠ®, O), (áŠ®áˆœáˆ­...  \n",
      "3  [(40414243, O), (3400, O), (áŠ á‹µáˆ«áˆ»áˆœáŠ­áˆ²áŠ®, O), (áŠ®áˆœáˆ­...  \n",
      "4  [(414243, O), (3600, O), (áŠ á‹µáˆ«áˆ»áˆœáŠ­áˆ²áŠ®, O), (áŠ®áˆœáˆ­áˆµ,...  \n"
     ]
    }
   ],
   "source": [
    "# Label the tokens in the DataFrame\n",
    "labeled_df = labeler.label_dataframe(df, 'Tokenized')\n",
    "print(\"Labeling completed. Sample labeled DataFrame:\\n\", labeled_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "etvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
